\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}%
\contentsline {section}{\numberline {1.1}The Problem}{5}{section.1.1}%
\contentsline {section}{\numberline {1.2}Contributions}{7}{section.1.2}%
\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}%
\contentsline {section}{\numberline {2.1}The supervised classification problem}{9}{section.2.1}%
\contentsline {section}{\numberline {2.2}Neural networks}{10}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Training algorithms}{12}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Loss functions}{13}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Backpropagation}{14}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Adversarial risk}{15}{section.2.3}%
\contentsline {section}{\numberline {2.4}Standard attacks on DNNs in literature}{18}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Fast Gradient Sign Method}{19}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Projected Gradient Descent}{19}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Benign overfitting and label noise}{21}{section.2.5}%
\contentsline {section}{\numberline {2.6}Dataset poisoning}{23}{section.2.6}%
\contentsline {chapter}{\numberline {3}Is Lipschitzness always beneficial for robustness?}{25}{chapter.3}%
\contentsline {chapter}{\numberline {4}Crafting Label Noise}{31}{chapter.4}%
\contentsline {section}{\numberline {4.1}Toy distribution}{31}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Classes far away from the decision boundary}{32}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Classes close to the decision boundary}{35}{subsection.4.1.2}%
\contentsline {section}{\numberline {4.2}Flipping to a new class in MNIST}{37}{section.4.2}%
\contentsline {section}{\numberline {4.3}Analysis using adversarial paths}{38}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Finding a path from a point to the boundary}{39}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Using adversarial paths to analyse poisons}{40}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}Adversarial Path Experiments}{42}{subsection.4.3.3}%
\contentsline {subsubsection}{0-1 MNIST}{42}{section*.15}%
\contentsline {subsubsection}{MNIST}{43}{section*.17}%
\contentsline {chapter}{\numberline {5}Future Work: A Meta-Learning Approach}{46}{chapter.5}%
\contentsline {chapter}{\numberline {6}Early Unsuccessful Experiments}{51}{chapter.6}%
\contentsline {section}{\numberline {6.1}Building graphs on training points}{51}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Building graphs on input space}{53}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Using Low Rank representations}{54}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Using the feature representations of a trained network}{55}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}Using the feature representations of a trained network as well as input space}{55}{subsection.6.1.4}%
\contentsline {section}{\numberline {6.2}Colouring trick}{56}{section.6.2}%
\contentsline {chapter}{Conclusion}{58}{chapter*.23}%
\contentsline {chapter}{Appendices}{68}{section*.25}%
\contentsline {chapter}{\numberline {A}Fitting Neural Networks to low dimensional data}{69}{appendix.a.A}%
