\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}%
\contentsline {section}{\numberline {1.1}The Problem}{7}{section.1.1}%
\contentsline {section}{\numberline {1.2}Contributions}{9}{section.1.2}%
\contentsline {chapter}{\numberline {2}Background}{10}{chapter.2}%
\contentsline {section}{\numberline {2.1}The supervised classification problem}{10}{section.2.1}%
\contentsline {section}{\numberline {2.2}Neural networks}{11}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Training algorithms}{12}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Loss functions}{13}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Backpropagation}{14}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Adversarial risk}{14}{section.2.3}%
\contentsline {section}{\numberline {2.4}Standard attacks for neural networks in literature}{17}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Fast Gradient Sign Method}{18}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Projected Gradient Descent}{18}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Benign Overfitting and label noise}{19}{section.2.5}%
\contentsline {section}{\numberline {2.6}Dataset poisoning}{21}{section.2.6}%
\contentsline {chapter}{\numberline {3}Is Lipschitzness always beneficial for robustness?}{22}{chapter.3}%
\contentsline {section}{\numberline {3.1}Improved bound with Lipschitzness Assumptions}{23}{section.3.1}%
\contentsline {section}{\numberline {3.2}Lipschitzness bounded by distance to the nearest point, of different label}{25}{section.3.2}%
\contentsline {chapter}{\numberline {4}Early Unsuccessful Experiments}{29}{chapter.4}%
\contentsline {section}{\numberline {4.1}Building graphs on training points}{29}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Building graphs on input space}{31}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Using Low Rank representations}{32}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}Using the feature representations of a trained network}{32}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}Using the feature representations of a trained network as well as input space}{33}{subsection.4.1.4}%
\contentsline {section}{\numberline {4.2}Min Coloring trick}{33}{section.4.2}%
\contentsline {chapter}{\numberline {5}Experimental results}{35}{chapter.5}%
\contentsline {section}{\numberline {5.1}Toy Distribution}{35}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Toy distribution with points far away from the decision boundary}{36}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Toy distribution with points close to the decision boundary}{38}{subsection.5.1.2}%
\contentsline {section}{\numberline {5.2}The worst poisons are not the ones producing pockets with the wrong label}{40}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Flipping to an 11th class in MNIST}{40}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Analysis using adversarial paths}{41}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Finding a path from a point to the boundary}{42}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Using adversarial paths to analyse poisons}{43}{subsection.5.3.2}%
\contentsline {subsection}{\numberline {5.3.3}The experiments}{44}{subsection.5.3.3}%
\contentsline {subsubsection}{0-1 MNIST}{44}{section*.19}%
\contentsline {subsubsection}{MNIST}{45}{section*.21}%
\contentsline {chapter}{\numberline {6}Future Work: A Meta-Learning Approach}{48}{chapter.6}%
\contentsline {chapter}{\numberline {7}Conclusion}{52}{chapter.7}%
