\contentsline {chapter}{\numberline {1}Introduction}{6}{chapter.1}%
\contentsline {section}{\numberline {1.1}The Problem}{6}{section.1.1}%
\contentsline {section}{\numberline {1.2}Contributions}{7}{section.1.2}%
\contentsline {chapter}{\numberline {2}Background}{9}{chapter.2}%
\contentsline {section}{\numberline {2.1}The supervised classification problem}{9}{section.2.1}%
\contentsline {section}{\numberline {2.2}Neural networks}{10}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Training algorithms}{12}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Loss functions}{12}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Backpropagation}{13}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Adversarial risk}{14}{section.2.3}%
\contentsline {section}{\numberline {2.4}Standard attacks for DNNs in literature}{16}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Fast Gradient Sign Method}{17}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Projected Gradient Descent}{18}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Benign Overfitting and label noise}{18}{section.2.5}%
\contentsline {section}{\numberline {2.6}Dataset poisoning}{20}{section.2.6}%
\contentsline {chapter}{\numberline {3}Is Lipschitzness always beneficial for robustness?}{22}{chapter.3}%
\contentsline {chapter}{\numberline {4}Experimental results}{28}{chapter.4}%
\contentsline {section}{\numberline {4.1}Toy Distribution}{28}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Toy distribution with points far away from the decision boundary}{29}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Toy distribution with points close to the decision boundary}{31}{subsection.4.1.2}%
\contentsline {section}{\numberline {4.2}The worst poisons are not the ones producing pockets with the wrong label}{33}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Flipping to an 11th class in MNIST}{33}{subsection.4.2.1}%
\contentsline {section}{\numberline {4.3}Analysis using adversarial paths}{34}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Finding a path from a point to the boundary}{35}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Using adversarial paths to analyse poisons}{36}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}The experiments}{37}{subsection.4.3.3}%
\contentsline {subsubsection}{0-1 MNIST}{37}{section*.15}%
\contentsline {subsubsection}{MNIST}{38}{section*.17}%
\contentsline {chapter}{\numberline {5}Future Work: A Meta-Learning Approach}{41}{chapter.5}%
\contentsline {chapter}{\numberline {6}Early Unsuccessful Experiments}{45}{chapter.6}%
\contentsline {section}{\numberline {6.1}Building graphs on training points}{45}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Building graphs on input space}{47}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Using Low Rank representations}{48}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Using the feature representations of a trained network}{48}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}Using the feature representations of a trained network as well as input space}{49}{subsection.6.1.4}%
\contentsline {section}{\numberline {6.2}Min Coloring trick}{49}{section.6.2}%
\contentsline {chapter}{\numberline {7}Conclusion}{51}{chapter.7}%
\contentsline {chapter}{Appendices}{58}{section*.25}%
\contentsline {section}{\numberline {7.1}Fitting Neural Networks to low dimensional data}{59}{section.7.1}%
