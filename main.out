\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{The Problem}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Contributions}{chapter.1}% 3
\BOOKMARK [0][-]{chapter.2}{Background}{}% 4
\BOOKMARK [1][-]{section.2.1}{The supervised classification problem}{chapter.2}% 5
\BOOKMARK [1][-]{section.2.2}{Neural networks}{chapter.2}% 6
\BOOKMARK [2][-]{subsection.2.2.1}{Training algorithms}{section.2.2}% 7
\BOOKMARK [2][-]{subsection.2.2.2}{Loss functions}{section.2.2}% 8
\BOOKMARK [2][-]{subsection.2.2.3}{Backpropagation}{section.2.2}% 9
\BOOKMARK [1][-]{section.2.3}{Adversarial risk}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.4}{Standard attacks on DNNs in literature}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.4.1}{Fast Gradient Sign Method}{section.2.4}% 12
\BOOKMARK [2][-]{subsection.2.4.2}{Projected Gradient Descent}{section.2.4}% 13
\BOOKMARK [1][-]{section.2.5}{Benign Overfitting and label noise}{chapter.2}% 14
\BOOKMARK [1][-]{section.2.6}{Dataset poisoning}{chapter.2}% 15
\BOOKMARK [0][-]{chapter.3}{Is Lipschitzness always beneficial for robustness?}{}% 16
\BOOKMARK [0][-]{chapter.4}{Experimental results}{}% 17
\BOOKMARK [1][-]{section.4.1}{Toy Distribution}{chapter.4}% 18
\BOOKMARK [2][-]{subsection.4.1.1}{Toy distribution with points far away from the decision boundary}{section.4.1}% 19
\BOOKMARK [2][-]{subsection.4.1.2}{Toy distribution with points close to the decision boundary}{section.4.1}% 20
\BOOKMARK [1][-]{section.4.2}{The worst poisons are not the ones producing pockets with the wrong label}{chapter.4}% 21
\BOOKMARK [2][-]{subsection.4.2.1}{Flipping to an 11th class in MNIST}{section.4.2}% 22
\BOOKMARK [1][-]{section.4.3}{Analysis using adversarial paths}{chapter.4}% 23
\BOOKMARK [2][-]{subsection.4.3.1}{Finding a path from a point to the boundary}{section.4.3}% 24
\BOOKMARK [2][-]{subsection.4.3.2}{Using adversarial paths to analyse poisons}{section.4.3}% 25
\BOOKMARK [2][-]{subsection.4.3.3}{The experiments}{section.4.3}% 26
\BOOKMARK [0][-]{chapter.5}{Future Work: A Meta-Learning Approach}{}% 27
\BOOKMARK [0][-]{chapter.6}{Early Unsuccessful Experiments}{}% 28
\BOOKMARK [1][-]{section.6.1}{Building graphs on training points}{chapter.6}% 29
\BOOKMARK [2][-]{subsection.6.1.1}{Building graphs on input space}{section.6.1}% 30
\BOOKMARK [2][-]{subsection.6.1.2}{Using Low Rank representations}{section.6.1}% 31
\BOOKMARK [2][-]{subsection.6.1.3}{Using the feature representations of a trained network}{section.6.1}% 32
\BOOKMARK [2][-]{subsection.6.1.4}{Using the feature representations of a trained network as well as input space}{section.6.1}% 33
\BOOKMARK [1][-]{section.6.2}{Min Coloring trick}{chapter.6}% 34
\BOOKMARK [0][-]{chapter.7}{Conclusion}{}% 35
\BOOKMARK [0][-]{section*.25}{Appendices}{}% 36
\BOOKMARK [1][-]{section.7.1}{Fitting Neural Networks to low dimensional data}{section*.25}% 37
